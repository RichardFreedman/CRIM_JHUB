{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4577f63f",
   "metadata": {},
   "source": [
    "## Presentation Types with Hidden Types\n",
    "## Also Network Visualization with Louvain Communities\n",
    "\n",
    "* March 2022 version\n",
    "\n",
    "    * Uses getDistance to identify `close matches` with side-by-side comparison of soggetti.  With a distance of \"1\", the soggetti `4, 1, 2, 3`, and `5, 1, 2, 3` will count as the same.  These are reported as \"flexed entries\" in a separate column.\n",
    "\n",
    "    * Labels Fuga, PEn, and ID according to time intervals.  \n",
    "    * If two entries are separated by more than 10 bars (80 offsets), the tool resets to a new pattern\n",
    "    * Finds time intervals between entries (expressed as offsets, like `8.0, 4.0, 8.0`)\n",
    "    * Finds melodic intervals between first note of successive entries in each pattern (like `P-5, P-8`)\n",
    "    * Counts number of entries\n",
    "    * Provides offset and measure/beat locations\n",
    "    * Sorts all presentation types by the order in which they appear in the piece\n",
    "    * Reports voice names of the entries, in order of their appearance\n",
    "    * Omits singleton soggetti (just one entry of a given motive in isolation)\n",
    "    \n",
    "    ALSO\n",
    "    \n",
    "    * Finds \"hidden\" types within a longer Fuga.  That is, if a 5-voice fuga also contains a PEN, it will label both of these as separate presentation type, along with all the relevant data noted above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d5c1fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved_csv folder already exists.\n"
     ]
    }
   ],
   "source": [
    "import intervals\n",
    "from intervals import * \n",
    "from intervals import main_objs\n",
    "import intervals.visualizations as viz\n",
    "import pandas as pd\n",
    "import re\n",
    "import altair as alt \n",
    "from ipywidgets import interact\n",
    "from pandas.io.json import json_normalize\n",
    "from pyvis.network import Network\n",
    "from IPython.display import display\n",
    "import requests\n",
    "import os\n",
    "import numpy as np\n",
    "import itertools\n",
    "from itertools import combinations\n",
    "import networkx as nx\n",
    "from community import community_louvain\n",
    "from copy import deepcopy\n",
    "MYDIR = (\"saved_csv\")\n",
    "CHECK_FOLDER = os.path.isdir(MYDIR)\n",
    "\n",
    "# If folder doesn't exist, then create it.\n",
    "if not CHECK_FOLDER:\n",
    "    os.makedirs(MYDIR)\n",
    "    print(\"created folder : \", MYDIR)\n",
    "\n",
    "else:\n",
    "    print(MYDIR, \"folder already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71dba07",
   "metadata": {},
   "source": [
    "#### The following are special functions used by the classifier.  Don't change them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e63137",
   "metadata": {},
   "source": [
    "## Load one Piece Here\n",
    "\n",
    "* Note that you can load from CRIM, or put a file in the **Music_Files** folder in the Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55fcd806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading remote score...\n",
      "Successfully imported https://raw.githubusercontent.com/CRIM-Project/CRIM-online/master/crim/static/mei/MEI_4.0/CRIM_Model_0001.mei\n",
      "{'title': 'Veni speciosam', 'composer': 'Lupi, Johannes'}\n"
     ]
    }
   ],
   "source": [
    "git_prefix = 'https://raw.githubusercontent.com/CRIM-Project/CRIM-online/master/crim/static/mei/MEI_4.0/'\n",
    "\n",
    "# just add the CRIM Piece ID here\n",
    "mei_file = 'CRIM_Model_0001.mei'\n",
    "\n",
    "\n",
    "url = git_prefix + mei_file\n",
    "# piece = importScore('Music_Files/Senfl_Ave_forCRIM.mei_msg.mei')\n",
    "piece = importScore(url)\n",
    "# piece = importScore('Music_Files/CRIM_Mass_0007_4.mei')\n",
    "\n",
    "print(piece.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c2a3547f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_test(piece, nr, mel_ng, entries, edit_distance_threshold, include_hidden_types):\n",
    "\n",
    "    \"\"\"This function uses several other functions to classify the entries in a given piece.\n",
    "    The output is a list, in order of offset, of each presentation type, including information about\n",
    "    measures/beats\n",
    "    starting offset\n",
    "    soggetti involved\n",
    "    melodic intervals of entry\n",
    "    time intervals of entry\n",
    "\n",
    "    set the length of the soggetti with `melodic_ngram_length`\n",
    "    set the maximum difference between similar soggetti with `edit_distance_threshold`\n",
    "    for chromatic vs diatonic, compound, and directed data in soggetti, see `interval_settings`\n",
    "    to include all the hidden PENs and IDS (those found within longer Fugas),\n",
    "    use `include_hidden_types == True`.\n",
    "    For faster (and simpler) listing of points of imitation without hidden forms, use `include_hidden_types == False`\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    # Classifier with Functions\n",
    "    points = pd.DataFrame(columns=['Composer',\n",
    "                 'Title',\n",
    "                 'First_Offset',\n",
    "                 'Measures_Beats',\n",
    "                 'Melodic_Entry_Intervals',\n",
    "                 'Offsets',\n",
    "                 'Soggetti',\n",
    "                 'Time_Entry_Intervals',\n",
    "                 'Voices',\n",
    "                 'Presentation_Type'])\n",
    "    points2 = pd.DataFrame()\n",
    "    \n",
    "    # new_offset_list = []\n",
    "#     nr = piece.getNoteRest()\n",
    "    det = piece.detailIndex(nr, offset=True)\n",
    "\n",
    "    # The following are now all set in the Notebook as argument\n",
    "    # durations and ngrams of durations\n",
    "    # dur = piece.getDuration(df=nr)\n",
    "    # dur_ng = piece.getNgrams(df=dur, n=3)\n",
    "\n",
    "    # ngrams of melodic entries\n",
    "    # for chromatic, use:\n",
    "    # piece.getMelodicEntries(interval_settings=('c', True, True), n=5)\n",
    "    #mel_ng = piece.getMelodicEntries(interval_settings=('c', True, True), n=5)\n",
    "    mels_stacked = entries.stack().to_frame()\n",
    "    mels_stacked.rename(columns =  {0:\"pattern\"}, inplace = True)\n",
    "\n",
    "    # edit distance, based on side-by-side comparison of melodic ngrams\n",
    "    # gets flexed and other similar soggetti\n",
    "    dist = piece.getDistance(entries)\n",
    "    dist_stack = dist.stack().to_frame()\n",
    "\n",
    "\n",
    "    # filter distances to threshold.  <2 is good\n",
    "    distance_factor = edit_distance_threshold + 1\n",
    "    filtered_dist_stack = dist_stack[dist_stack[0] < distance_factor]\n",
    "    filtered_dist = filtered_dist_stack.reset_index()\n",
    "    filtered_dist.rename(columns =  {'level_0':\"source\", 'level_1':'match'}, inplace = True)\n",
    "\n",
    "    # Group the filtered distanced patterns\n",
    "    full_list_of_matches = filtered_dist.groupby('source')['match'].apply(list).reset_index()\n",
    "\n",
    "    if include_hidden_types == False:\n",
    "\n",
    "        for matches in full_list_of_matches[\"match\"]:\n",
    "            related_entry_list = mels_stacked[mels_stacked['pattern'].isin(matches)]\n",
    "            entry_array = related_entry_list.reset_index(level=1).rename(columns = {'level_1': \"voice\", 0: \"pattern\"})\n",
    "            offset_list = entry_array.index.to_list()\n",
    "            split_list = list(split_by_threshold(offset_list))\n",
    "            for item in split_list:\n",
    "\n",
    "                # print(item)\n",
    "\n",
    "                offset_gap_limit = 40.0\n",
    "            \n",
    "                \n",
    "            # here is the list of starting offsets of the original set of entries:  slist\n",
    "# \n",
    "                temp = temp_dict_of_details(item, entry_array, det, matches, piece)\n",
    "                a = temp[\"Time_Entry_Intervals\"] \n",
    "                if (all(x < offset_gap_limit for x in a)):\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "                    points = points.append(temp, ignore_index=True)\n",
    "                    points['Presentation_Type'] = points['Time_Entry_Intervals'].apply(classify_by_offset)\n",
    "                    # points.drop_duplicates(subset=[\"First_Offset\"], keep='first', inplace = True)\n",
    "                    points = points[points['Offsets'].apply(len) > 1]\n",
    "\n",
    "        points[\"Offsets_Key\"] = points[\"Offsets\"].apply(offset_joiner)\n",
    "        points.drop_duplicates(subset=[\"Offsets_Key\"], keep='first', inplace = True)\n",
    "        points['Flexed_Entries'] = points[\"Soggetti\"].apply(len) > 1\n",
    "        points[\"Number_Entries\"] = points[\"Offsets\"].apply(len)\n",
    "        col_order = ['Composer',\n",
    "                 'Title',\n",
    "                 'First_Offset',\n",
    "                 'Measures_Beats',\n",
    "                 'Melodic_Entry_Intervals',\n",
    "                 'Offsets',\n",
    "                 'Soggetti',\n",
    "                 'Time_Entry_Intervals',\n",
    "                 'Voices',\n",
    "                 'Presentation_Type',\n",
    "                  'Number_Entries',\n",
    "                'Flexed_Entries']\n",
    "        points = points.reindex(columns=col_order).sort_values(\"First_Offset\").reset_index(drop=True)\n",
    "        # return points\n",
    "\n",
    "    elif include_hidden_types == True:\n",
    "        hidden_types_list = [\"PEN\", \"ID\"]\n",
    "\n",
    "        for matches in full_list_of_matches[\"match\"]:\n",
    "            related_entry_list = mels_stacked[mels_stacked['pattern'].isin(matches)]\n",
    "            entry_array = related_entry_list.reset_index(level=1).rename(columns = {'level_1': \"voice\", 0: \"pattern\"})\n",
    "            offset_list = entry_array.index.to_list()\n",
    "            split_list = list(split_by_threshold(offset_list))\n",
    "            for item in split_list:\n",
    "            # here is the list of starting offsets of the original set of entries:  slist\n",
    "\n",
    "                offset_gap_limit = 40.0\n",
    "                \n",
    "                temp = temp_dict_of_details(item, entry_array, det, matches, piece)\n",
    "\n",
    "                b = temp[\"Time_Entry_Intervals\"] \n",
    "                if (all(x < offset_gap_limit for x in b)):\n",
    "\n",
    "\n",
    "                    points = points.append(temp, ignore_index=True)\n",
    "                    points['Presentation_Type'] = points['Time_Entry_Intervals'].apply(classify_by_offset)\n",
    "                    # points.drop_duplicates(subset=[\"First_Offset\"], keep='first', inplace = True)\n",
    "                    points = points[points['Offsets'].apply(len) > 1]\n",
    "        # return(points)\n",
    "\n",
    "        \n",
    "            for item in split_list:\n",
    "    # #         # here is the list of starting offsets of the original set of entries:  slist\n",
    "                offset_gap_limit = 40.0\n",
    "\n",
    "                temp = temp_dict_of_details(item, entry_array, det, matches, piece)\n",
    "\n",
    "                c = temp[\"Time_Entry_Intervals\"] \n",
    "                if (all(x < offset_gap_limit for x in c)):\n",
    "\n",
    "                    lto = len(temp[\"Offsets\"])\n",
    "                    if lto > 2 :\n",
    "                        for r in range(3, 6):\n",
    "                            list_combinations = list(combinations(item, r))\n",
    "                            for slist in list_combinations:\n",
    "\n",
    "                                temp = temp_dict_of_details(slist, entry_array, det, matches, piece)\n",
    "\n",
    "                                temp[\"Presentation_Type\"] = classify_by_offset(temp['Time_Entry_Intervals'])\n",
    "                                # print(temp)\n",
    "\n",
    "                                if 'PEN' in temp[\"Presentation_Type\"]:\n",
    "                                    points2 = points2.append(temp, ignore_index=True)\n",
    "                                if 'ID' in temp[\"Presentation_Type\"]:\n",
    "                                    points2 = points2.append(temp, ignore_index=True)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        points2 = points2[points2[\"Presentation_Type\"].isin(hidden_types_list)]\n",
    "        # return(points2)\n",
    "\n",
    "        \n",
    "        points_combined = points.append(points2, ignore_index=True)\n",
    "        points_combined[\"Offsets_Key\"] = points_combined[\"Offsets\"].apply(offset_joiner)\n",
    "        points_combined.drop_duplicates(subset=[\"Offsets_Key\"], keep='first', inplace = True)\n",
    "        points_combined['Flexed_Entries'] = points_combined[\"Soggetti\"].apply(len) > 1\n",
    "        points_combined[\"Number_Entries\"] = points_combined[\"Offsets\"].apply(len)\n",
    "        col_order = ['Composer',\n",
    "                 'Title',\n",
    "                 'First_Offset',\n",
    "                 'Measures_Beats',\n",
    "                 'Melodic_Entry_Intervals',\n",
    "                 'Offsets',\n",
    "                 'Soggetti',\n",
    "                 'Time_Entry_Intervals',\n",
    "                 'Voices',\n",
    "                 'Presentation_Type',\n",
    "                  'Number_Entries',\n",
    "                'Flexed_Entries']\n",
    "        # points_combined = points_combined.sort_values(\"First_Offset\").reset_index(drop=True)\n",
    "        points_combined = points_combined.reindex(columns=col_order).sort_values(\"First_Offset\").reset_index(drop=True)\n",
    "        return points_combined\n",
    "        \n",
    "    \n",
    "\n",
    "                        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e795be",
   "metadata": {},
   "source": [
    "## Run the Classifier Here\n",
    "\n",
    "- set the length of the soggetti with `melodic_ngram_length`\n",
    "- set the maximum difference between similar soggetti with `edit_distance_threshold`\n",
    "- for chromatic vs diatonic, compound, and directed data in soggetti, see `interval_settings`\n",
    "- to include all the hidden PENs and IDS (those found within longer Fugas, use `include_hidden_types == True`.  \n",
    "- for faster (and simpler) listing of points of imitation without hidden forms, use `include_hidden_types == False`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4fa190",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b7bde44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "mylist = [2.0, 6.0, 10.0]\n",
    "offset_gap_limit = 20.0\n",
    "if (all(x < offset_gap_limit for x in mylist)):\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1547e63b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e9c6f1b3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "include_hidden_types = True\n",
    "combine_unisons = True\n",
    "melodic_ngram_length = 4\n",
    "edit_distance_threshold = 1\n",
    "nr = piece.getNoteRest(combineUnisons=combine_unisons)\n",
    "dur = piece.getDuration(df=nr)\n",
    "mel = piece.getMelodic(df=nr, kind='d', end=False)\n",
    "mel_ng = piece.getNgrams(df=mel, n=melodic_ngram_length)\n",
    "entries = piece.getEntries(mel_ng)\n",
    "output = class_test(piece, nr, mel_ng, entries, edit_distance_threshold, include_hidden_types)\n",
    "# dur.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c899bc7",
   "metadata": {},
   "source": [
    "#### Below Find Source Code and Explanation of the Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "76e0a43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Composer</th>\n",
       "      <th>Title</th>\n",
       "      <th>First_Offset</th>\n",
       "      <th>Measures_Beats</th>\n",
       "      <th>Melodic_Entry_Intervals</th>\n",
       "      <th>Offsets</th>\n",
       "      <th>Soggetti</th>\n",
       "      <th>Time_Entry_Intervals</th>\n",
       "      <th>Voices</th>\n",
       "      <th>Presentation_Type</th>\n",
       "      <th>Number_Entries</th>\n",
       "      <th>Flexed_Entries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lupi, Johannes</td>\n",
       "      <td>Veni speciosam</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1/1.0, 2/3.0, 5/1.0, 6/3.0, 9/2.0, 10/1.0]</td>\n",
       "      <td>[P-4, P-5, P-4, P4, P8]</td>\n",
       "      <td>[0.0, 12.0, 32.0, 44.0, 66.0, 72.0]</td>\n",
       "      <td>[(5, -2, 2, 3), (4, -2, 2, 3)]</td>\n",
       "      <td>[12.0, 20.0, 12.0, 22.0, 6.0]</td>\n",
       "      <td>[Superius, Contratenor, PrimusTenor, Bassus, S...</td>\n",
       "      <td>FUGA</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lupi, Johannes</td>\n",
       "      <td>Veni speciosam</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1/1.0, 2/3.0, 5/1.0, 6/3.0]</td>\n",
       "      <td>[P-4, P-5, P-4]</td>\n",
       "      <td>[0.0, 12.0, 32.0, 44.0]</td>\n",
       "      <td>[(5, -2, 2, 3), (4, -2, 2, 3)]</td>\n",
       "      <td>[12.0, 20.0, 12.0]</td>\n",
       "      <td>[Superius, Contratenor, PrimusTenor, Bassus]</td>\n",
       "      <td>ID</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lupi, Johannes</td>\n",
       "      <td>Veni speciosam</td>\n",
       "      <td>94.0</td>\n",
       "      <td>[12/4.0, 16/4.0]</td>\n",
       "      <td>[P4]</td>\n",
       "      <td>[94.0, 126.0]</td>\n",
       "      <td>[(-3, 2, 2, -2)]</td>\n",
       "      <td>[32.0]</td>\n",
       "      <td>[Bassus, Bassus]</td>\n",
       "      <td>FUGA</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lupi, Johannes</td>\n",
       "      <td>Veni speciosam</td>\n",
       "      <td>138.0</td>\n",
       "      <td>[18/2.0, 21/2.0, 24/2.0]</td>\n",
       "      <td>[M9, M-9]</td>\n",
       "      <td>[138.0, 162.0, 186.0]</td>\n",
       "      <td>[(-2, -3, 2, 2), (-2, -3, 3, 2)]</td>\n",
       "      <td>[24.0, 24.0]</td>\n",
       "      <td>[PrimusTenor, Superius, PrimusTenor]</td>\n",
       "      <td>PEN</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lupi, Johannes</td>\n",
       "      <td>Veni speciosam</td>\n",
       "      <td>138.0</td>\n",
       "      <td>[18/2.0, 18/4.0, 20/4.0, 21/2.0]</td>\n",
       "      <td>[P-4, P8, P5]</td>\n",
       "      <td>[138.0, 142.0, 158.0, 162.0]</td>\n",
       "      <td>[(-2, -3, 2, 2), (-2, -3, 3, 2)]</td>\n",
       "      <td>[4.0, 16.0, 4.0]</td>\n",
       "      <td>[PrimusTenor, Bassus, Contratenor, Superius]</td>\n",
       "      <td>ID</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Lupi, Johannes</td>\n",
       "      <td>Veni speciosam</td>\n",
       "      <td>978.0</td>\n",
       "      <td>[122/2.0, 122/4.0, 123/2.0]</td>\n",
       "      <td>[P1, P8]</td>\n",
       "      <td>[978.0, 982.0, 986.0]</td>\n",
       "      <td>[(2, -2, -3, 2)]</td>\n",
       "      <td>[4.0, 4.0]</td>\n",
       "      <td>[SecundusTenor, PrimusTenor, Superius]</td>\n",
       "      <td>PEN</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Lupi, Johannes</td>\n",
       "      <td>Veni speciosam</td>\n",
       "      <td>978.0</td>\n",
       "      <td>[122/2.0, 122/4.0, 123/2.0, 125/1.0, 126/4.0, ...</td>\n",
       "      <td>[P1, P8, P-5, P-5, P-8, P8, P1]</td>\n",
       "      <td>[978.0, 982.0, 986.0, 1000.0, 1014.0, 1020.0, ...</td>\n",
       "      <td>[(2, -2, -3, 2)]</td>\n",
       "      <td>[4.0, 4.0, 14.0, 14.0, 6.0, 10.0, 8.0]</td>\n",
       "      <td>[SecundusTenor, PrimusTenor, Superius, Contrat...</td>\n",
       "      <td>FUGA</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Lupi, Johannes</td>\n",
       "      <td>Veni speciosam</td>\n",
       "      <td>978.0</td>\n",
       "      <td>[122/2.0, 123/2.0, 128/4.0, 129/4.0]</td>\n",
       "      <td>[P8, M-9, P1]</td>\n",
       "      <td>[978.0, 986.0, 1030.0, 1038.0]</td>\n",
       "      <td>[(2, -2, -3, 2)]</td>\n",
       "      <td>[8.0, 44.0, 8.0]</td>\n",
       "      <td>[SecundusTenor, Superius, Contratenor, Secundu...</td>\n",
       "      <td>ID</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Lupi, Johannes</td>\n",
       "      <td>Veni speciosam</td>\n",
       "      <td>982.0</td>\n",
       "      <td>[122/4.0, 125/1.0, 127/3.0, 129/4.0]</td>\n",
       "      <td>[P4, P-12, P8]</td>\n",
       "      <td>[982.0, 1000.0, 1020.0, 1038.0]</td>\n",
       "      <td>[(2, -2, -3, 2)]</td>\n",
       "      <td>[18.0, 20.0, 18.0]</td>\n",
       "      <td>[PrimusTenor, Contratenor, Bassus, SecundusTenor]</td>\n",
       "      <td>ID</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Lupi, Johannes</td>\n",
       "      <td>Veni speciosam</td>\n",
       "      <td>986.0</td>\n",
       "      <td>[123/2.0, 125/1.0, 126/4.0]</td>\n",
       "      <td>[P-5, P-5]</td>\n",
       "      <td>[986.0, 1000.0, 1014.0]</td>\n",
       "      <td>[(2, -2, -3, 2)]</td>\n",
       "      <td>[14.0, 14.0]</td>\n",
       "      <td>[Superius, Contratenor, SecundusTenor]</td>\n",
       "      <td>PEN</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Composer           Title  First_Offset  \\\n",
       "0    Lupi, Johannes  Veni speciosam           0.0   \n",
       "1    Lupi, Johannes  Veni speciosam           0.0   \n",
       "2    Lupi, Johannes  Veni speciosam          94.0   \n",
       "3    Lupi, Johannes  Veni speciosam         138.0   \n",
       "4    Lupi, Johannes  Veni speciosam         138.0   \n",
       "..              ...             ...           ...   \n",
       "106  Lupi, Johannes  Veni speciosam         978.0   \n",
       "107  Lupi, Johannes  Veni speciosam         978.0   \n",
       "108  Lupi, Johannes  Veni speciosam         978.0   \n",
       "109  Lupi, Johannes  Veni speciosam         982.0   \n",
       "110  Lupi, Johannes  Veni speciosam         986.0   \n",
       "\n",
       "                                        Measures_Beats  \\\n",
       "0          [1/1.0, 2/3.0, 5/1.0, 6/3.0, 9/2.0, 10/1.0]   \n",
       "1                         [1/1.0, 2/3.0, 5/1.0, 6/3.0]   \n",
       "2                                     [12/4.0, 16/4.0]   \n",
       "3                             [18/2.0, 21/2.0, 24/2.0]   \n",
       "4                     [18/2.0, 18/4.0, 20/4.0, 21/2.0]   \n",
       "..                                                 ...   \n",
       "106                        [122/2.0, 122/4.0, 123/2.0]   \n",
       "107  [122/2.0, 122/4.0, 123/2.0, 125/1.0, 126/4.0, ...   \n",
       "108               [122/2.0, 123/2.0, 128/4.0, 129/4.0]   \n",
       "109               [122/4.0, 125/1.0, 127/3.0, 129/4.0]   \n",
       "110                        [123/2.0, 125/1.0, 126/4.0]   \n",
       "\n",
       "             Melodic_Entry_Intervals  \\\n",
       "0            [P-4, P-5, P-4, P4, P8]   \n",
       "1                    [P-4, P-5, P-4]   \n",
       "2                               [P4]   \n",
       "3                          [M9, M-9]   \n",
       "4                      [P-4, P8, P5]   \n",
       "..                               ...   \n",
       "106                         [P1, P8]   \n",
       "107  [P1, P8, P-5, P-5, P-8, P8, P1]   \n",
       "108                    [P8, M-9, P1]   \n",
       "109                   [P4, P-12, P8]   \n",
       "110                       [P-5, P-5]   \n",
       "\n",
       "                                               Offsets  \\\n",
       "0                  [0.0, 12.0, 32.0, 44.0, 66.0, 72.0]   \n",
       "1                              [0.0, 12.0, 32.0, 44.0]   \n",
       "2                                        [94.0, 126.0]   \n",
       "3                                [138.0, 162.0, 186.0]   \n",
       "4                         [138.0, 142.0, 158.0, 162.0]   \n",
       "..                                                 ...   \n",
       "106                              [978.0, 982.0, 986.0]   \n",
       "107  [978.0, 982.0, 986.0, 1000.0, 1014.0, 1020.0, ...   \n",
       "108                     [978.0, 986.0, 1030.0, 1038.0]   \n",
       "109                    [982.0, 1000.0, 1020.0, 1038.0]   \n",
       "110                            [986.0, 1000.0, 1014.0]   \n",
       "\n",
       "                             Soggetti                    Time_Entry_Intervals  \\\n",
       "0      [(5, -2, 2, 3), (4, -2, 2, 3)]           [12.0, 20.0, 12.0, 22.0, 6.0]   \n",
       "1      [(5, -2, 2, 3), (4, -2, 2, 3)]                      [12.0, 20.0, 12.0]   \n",
       "2                    [(-3, 2, 2, -2)]                                  [32.0]   \n",
       "3    [(-2, -3, 2, 2), (-2, -3, 3, 2)]                            [24.0, 24.0]   \n",
       "4    [(-2, -3, 2, 2), (-2, -3, 3, 2)]                        [4.0, 16.0, 4.0]   \n",
       "..                                ...                                     ...   \n",
       "106                  [(2, -2, -3, 2)]                              [4.0, 4.0]   \n",
       "107                  [(2, -2, -3, 2)]  [4.0, 4.0, 14.0, 14.0, 6.0, 10.0, 8.0]   \n",
       "108                  [(2, -2, -3, 2)]                        [8.0, 44.0, 8.0]   \n",
       "109                  [(2, -2, -3, 2)]                      [18.0, 20.0, 18.0]   \n",
       "110                  [(2, -2, -3, 2)]                            [14.0, 14.0]   \n",
       "\n",
       "                                                Voices Presentation_Type  \\\n",
       "0    [Superius, Contratenor, PrimusTenor, Bassus, S...              FUGA   \n",
       "1         [Superius, Contratenor, PrimusTenor, Bassus]                ID   \n",
       "2                                     [Bassus, Bassus]              FUGA   \n",
       "3                 [PrimusTenor, Superius, PrimusTenor]               PEN   \n",
       "4         [PrimusTenor, Bassus, Contratenor, Superius]                ID   \n",
       "..                                                 ...               ...   \n",
       "106             [SecundusTenor, PrimusTenor, Superius]               PEN   \n",
       "107  [SecundusTenor, PrimusTenor, Superius, Contrat...              FUGA   \n",
       "108  [SecundusTenor, Superius, Contratenor, Secundu...                ID   \n",
       "109  [PrimusTenor, Contratenor, Bassus, SecundusTenor]                ID   \n",
       "110             [Superius, Contratenor, SecundusTenor]               PEN   \n",
       "\n",
       "     Number_Entries  Flexed_Entries  \n",
       "0                 6            True  \n",
       "1                 4            True  \n",
       "2                 2           False  \n",
       "3                 3            True  \n",
       "4                 4            True  \n",
       "..              ...             ...  \n",
       "106               3           False  \n",
       "107               8           False  \n",
       "108               4           False  \n",
       "109               4           False  \n",
       "110               3           False  \n",
       "\n",
       "[111 rows x 12 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230179ae",
   "metadata": {},
   "source": [
    "### Run Classifier on Several Pieces at Once\n",
    "\n",
    "Results are combined into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cea1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output[\"Presentation_Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b665f73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "git_prefix = 'https://raw.githubusercontent.com/CRIM-Project/CRIM-online/master/crim/static/mei/MEI_4.0/'\n",
    "\n",
    "# piece = importScore('Music_Files/CRIM_Mass_0007_4.mei')\n",
    "piece_list =  ['CRIM_Mass_0005_3.mei',\n",
    "             'CRIM_Mass_0005_4.mei',\n",
    "             'CRIM_Mass_0005_5.mei',\n",
    "             'CRIM_Model_0001.mei',\n",
    "             'CRIM_Mass_0002_1.mei',\n",
    "             'CRIM_Mass_0002_2.mei',\n",
    "             'CRIM_Mass_0002_3.mei',\n",
    "             'CRIM_Mass_0002_4.mei',\n",
    "             'CRIM_Mass_0002_5.mei',\n",
    "             'CRIM_Model_0015.mei',\n",
    "             'CRIM_Mass_0013_1.mei',\n",
    "             'CRIM_Mass_0013_2.mei',\n",
    "             'CRIM_Mass_0013_3.mei',\n",
    "             'CRIM_Mass_0013_4.mei',\n",
    "             'CRIM_Mass_0013_5.mei',\n",
    "             'CRIM_Model_0019.mei',\n",
    "             'CRIM_Mass_0019_1.mei',\n",
    "             'CRIM_Mass_0019_2.mei',\n",
    "             'CRIM_Mass_0019_3.mei',\n",
    "             'CRIM_Mass_0019_4.mei',\n",
    "             'CRIM_Mass_0019_5.mei']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb0e487",
   "metadata": {},
   "outputs": [],
   "source": [
    "git_prefix = 'https://raw.githubusercontent.com/CRIM-Project/CRIM-online/master/crim/static/mei/MEI_4.0/'\n",
    "\n",
    "piece_list = ['CRIM_Model_0019.mei',\n",
    "             'CRIM_Mass_0019_1.mei',\n",
    "             'CRIM_Mass_0019_2.mei',\n",
    "             'CRIM_Mass_0019_3.mei',\n",
    "             'CRIM_Mass_0019_4.mei',\n",
    "             'CRIM_Mass_0019_5.mei']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aedb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "include_hidden_types = False\n",
    "melodic_ngram_length = 4\n",
    "edit_distance_threshold = 0\n",
    "final = pd.DataFrame()\n",
    "for work in piece_list:\n",
    "    url = git_prefix + work\n",
    "    piece = importScore(url)   \n",
    "    nr = piece.getNoteRest(combineUnisons=True)\n",
    "    dur = piece.getDuration(df=nr)\n",
    "    mel = piece.getMelodic(df=nr)\n",
    "    mel_ng = piece.getMelodicEntries(interval_settings=('d', True, True), n=melodic_ngram_length)\n",
    "    output = classify_entries_as_presentation_types(piece, nr, mel_ng, edit_distance_threshold, include_hidden_types)\n",
    "    final = final.append(output, ignore_index=True)\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12e3324",
   "metadata": {},
   "outputs": [],
   "source": [
    "final[\"MINT\"] = final[\"Melodic_Entry_Intervals\"].apply(joiner)\n",
    "final[\"TINT\"] = final[\"Time_Entry_Intervals\"].apply(joiner)\n",
    "\n",
    "final['SOG'] = final['Soggetti'].apply(clean_melody)\n",
    "final['ALL'] = final[\"MINT\"] + '_' + final[\"TINT\"] + '_' + final['SOG']\n",
    "\n",
    "final[\"ALL_INT\"] = final[\"MINT\"] + '_' + final[\"TINT\"]\n",
    "final[\"ALL_SOG\"] = final[\"MINT\"] + '_' + final[\"SOG\"]\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e26aaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = final.loc[final['Number_Entries'] < 20] \n",
    "filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff9d5d6",
   "metadata": {},
   "source": [
    "### Network Visualization with Louvain Communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e26ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f2 = filtered.groupby('MINT')['Title'].apply(list).reset_index()\n",
    "f2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d0e559",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = f2.Title.apply(lambda x: list(combinations(x, 2)))\n",
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2af3a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs2 = pairs.explode().dropna()\n",
    "pairs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f912b268",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_pairs = pairs.explode().dropna().unique()\n",
    "unique_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656d1122",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(unique_pairs).isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1960f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_communities(G):\n",
    "    G = deepcopy(G)\n",
    "    partition = community_louvain.best_partition(G)\n",
    "    nx.set_node_attributes(G, partition, \"group\")\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f04d357",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyvis_graph = Network(notebook=True, width=\"1800\", height=\"1400\", bgcolor=\"white\", font_color=\"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02da53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_edges_from(unique_pairs)\n",
    "G = add_communities(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74820ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyvis_graph.from_nx(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d87adc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pyvis_graph.show('MINT.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be4ecf0",
   "metadata": {},
   "source": [
    "#### Below is Development Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b6712a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = output.loc[output['Number_Entries'] < 4] \n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718a571c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.loc[output['Presentation_Type'] == \"PEN\"] \n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa6b8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_diffs = [2.0, 1.0, 2.0, 3.0, 5.0, 6.0]\n",
    "# some_list[start:stop:step]\n",
    "alt_list = offset_diffs[::2]\n",
    "alt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33447a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this works with ONE list of offsets\n",
    "\n",
    "points2 = pd.DataFrame()\n",
    "split_list = [90.0, 94.0, 102.0, 106.0, 134.0, 146.0, 162.0]\n",
    "\n",
    "l = len(split_list)  \n",
    "for r in range(3, l):\n",
    "    list_combinations = list(combinations(split_list, r))\n",
    "#             combo_time_ints = []\n",
    "    for combo in list_combinations:\n",
    "        combo_time_ints = numpy.diff(combo).tolist()\n",
    "        combo_array = entry_array[entry_array.index.get_level_values(0).isin(combo)]\n",
    "        combo_voice_list = combo_array['voice'].to_list()\n",
    "        combo_patterns = combo_array['pattern']\n",
    "        unique_combo_patterns = list(set(combo_patterns))\n",
    "        tone_coordinates =  list(zip(combo, combo_voice_list))\n",
    "# tone_coordinates.ffill(inplace=True)\n",
    "        mel_ints = find_entry_int_distance(tone_coordinates, piece)\n",
    "        hidden_type = classify_by_offset(combo_time_ints)\n",
    "\n",
    "        meas_beat = det[det.index.get_level_values('Offset').isin(combo)]\n",
    "        mb2 = meas_beat.reset_index()\n",
    "        mb2['mb'] = mb2[\"Measure\"].astype(str) + \"/\" + mb2[\"Beat\"].astype(str)\n",
    "        meas_beat_list = mb2['mb'].to_list()\n",
    "\n",
    "        combo_temp = {'First_Offset': combo[0], \n",
    "            'Offsets': combo, \n",
    "            'Measures_Beats': meas_beat_list,\n",
    "            'Presentation_Type': hidden_type,\n",
    "            \"Soggetti\": unique_combo_patterns,\n",
    "            'Voices': combo_voice_list, \n",
    "            'Time_Entry_Intervals': combo_time_ints, \n",
    "            'Melodic_Entry_Intervals': mel_ints}\n",
    "\n",
    "        if 'PEN' in hidden_type:\n",
    "            points2 = points2.append(combo_temp, ignore_index=True).sort_values(\"First_Offset\")\n",
    "#             points2 = points2[points2['Offsets'].apply(len) > 1]\n",
    "        if 'ID' in hidden_type:\n",
    "            points2 = points2.append(combo_temp, ignore_index=True).sort_values(\"First_Offset\")\n",
    "#             points2 = points2[points2['Offsets'].apply(len) > 1]\n",
    "        \n",
    "        \n",
    "# combo_time_ints\n",
    "# combo_array\n",
    "# # combo_voice_list\n",
    "# # combo_patterns\n",
    "# # unique_combo_patterns\n",
    "# # tone_coordinates\n",
    "# # mel_ints\n",
    "# # combo_temp\n",
    "points2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28babf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this finds hidden fugas.  \n",
    "# try to run each of the first set of results above ('points') through this tool, then append the \n",
    "# new results to the full DF, and sort again.  \n",
    "# mark each long pattern with 'has hidden pattern' boolean?  or ?\n",
    "\n",
    "sample_list = points[\"Offsets\"][4]\n",
    "\n",
    "hidden_pts = []\n",
    "n = len(sample_list)\n",
    "for item in range(3, n):\n",
    "    list_combinations = list(combinations(sample_list, item))\n",
    "    for group in list_combinations:\n",
    "        group_time_ints = numpy.diff(group).tolist()\n",
    "        hidden_type = classify_by_offset(group_time_ints)\n",
    "        if 'PEN' in hidden_type:\n",
    "            print(group)\n",
    "            print(group_time_ints)\n",
    "            print(hidden_type)\n",
    "            hidden_pts.append(group_time_ints)\n",
    "        if 'ID' in hidden_type:\n",
    "            print(group)\n",
    "            print(group_time_ints)\n",
    "            print(hidden_type)\n",
    "            hidden_pts.append(group_time_ints)\n",
    "        \n",
    "\n",
    "list_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a374dad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_entries_as_presentation_types(piece):\n",
    "    # Classifier with Functions\n",
    "    points = pd.DataFrame()\n",
    "    points2 = pd.DataFrame()\n",
    "    # new_offset_list = []\n",
    "    nr = piece.getNoteRest()\n",
    "    det = piece.detailIndex(nr, offset=True)\n",
    "\n",
    "    # durations and ngrams of durations\n",
    "    dur = piece.getDuration(df=nr)\n",
    "    dur_ng = piece.getNgrams(df=dur, n=4)\n",
    "\n",
    "    # ngrams of melodic entries\n",
    "    # for chromatic, use:\n",
    "    # piece.getMelodicEntries(interval_settings=('c', True, True), n=5)\n",
    "    mel = piece.getMelodicEntries(n=4)\n",
    "    mels_stacked = mel.stack().to_frame()\n",
    "    mels_stacked.rename(columns =  {0:\"pattern\"}, inplace = True)\n",
    "\n",
    "    # edit distance, based on side-by-side comparison of melodic ngrams\n",
    "    # gets flexed and other similar soggetti\n",
    "    dist = piece.getDistance(mel)\n",
    "    dist_stack = dist.stack().to_frame()\n",
    "\n",
    "\n",
    "    # filter distances to threshold.  <2 is good\n",
    "    filtered_dist_stack = dist_stack[dist_stack[0] < 2]\n",
    "    filtered_dist = filtered_dist_stack.reset_index()\n",
    "    filtered_dist.rename(columns =  {'level_0':\"source\", 'level_1':'match'}, inplace = True)\n",
    "\n",
    "    # Group the filtered distanced patterns\n",
    "    full_list_of_matches = filtered_dist.groupby('source')['match'].apply(list).reset_index()\n",
    "\n",
    "    for matches in full_list_of_matches[\"match\"]:\n",
    "        related_entry_list = mels_stacked[mels_stacked['pattern'].isin(matches)]\n",
    "        entry_array = related_entry_list.reset_index(level=1).rename(columns = {'level_1': \"voice\", 0: \"pattern\"})\n",
    "        offset_list = entry_array.index.to_list()\n",
    "        split_list = list(split_by_threshold(offset_list))\n",
    "        # here is the list of starting offsets of the original set of entries:  slist\n",
    "        slist = split_list[0]\n",
    "        temp = temp_dict_of_details(slist, entry_array, det, matches)\n",
    "\n",
    "        points = points.append(temp, ignore_index=True)\n",
    "        points['Presentation_Type'] = points['Time_Entry_Intervals'].apply(classify_by_offset)\n",
    "        points.drop_duplicates(subset=[\"First_Offset\"], keep='first', inplace = True)\n",
    "        points = points[points['Offsets'].apply(len) > 1]\n",
    "\n",
    "        l = len(slist)\n",
    "        if l > 2:\n",
    "            for r in range(3, l):\n",
    "    #             list_combinations = list(combinations(slist, r))\n",
    "                list_combinations = list(combinations(slist, r))\n",
    "                for slist in list_combinations:\n",
    "\n",
    "                    temp = temp_dict_of_details(slist, entry_array, det, matches)\n",
    "\n",
    "                    temp[\"Presentation_Type\"] = classify_by_offset(temp['Time_Entry_Intervals'])\n",
    "\n",
    "                    if 'PEN' in temp[\"Presentation_Type\"]:\n",
    "                        points2 = points2.append(temp, ignore_index=True)#.sort_values(\"First_Offset\")\n",
    "    #                     points = points.append(combo_temp, ignore_index=True).sort_values(\"First_Offset\")\n",
    "                        points2 = points2[points2['Offsets'].apply(len) > 1]\n",
    "                    if 'ID' in temp[\"Presentation_Type\"]:\n",
    "                        points2 = points2.append(combo_temp, ignore_index=True)#.sort_values(\"First_Offset\")\n",
    "    #                     points = points.append(combo_temp, ignore_index=True).sort_values(\"First_Offset\")\n",
    "                points2.sort_values(\"First_Offset\")\n",
    "                points2.drop_duplicates(subset=[\"First_Offset\"], keep='first', inplace = True)\n",
    "\n",
    "    points_combined = points.append(points2, ignore_index=True).sort_values(\"First_Offset\").reset_index(drop=True)\n",
    "    points_combined['Flexed_Entries'] = points_combined[\"Soggetti\"].apply(len) > 1\n",
    "    points_combined[\"Number_Entries\"] = points[\"Offsets\"].apply(len)     \n",
    "    return points2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c6bcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This test works\n",
    "\n",
    "points = pd.DataFrame()\n",
    "points2 = pd.DataFrame()\n",
    "# new_offset_list = []\n",
    "nr = piece.getNoteRest()\n",
    "det = piece.detailIndex(nr, offset=True)\n",
    "\n",
    "# durations and ngrams of durations\n",
    "dur = piece.getDuration(df=nr)\n",
    "dur_ng = piece.getNgrams(df=dur, n=4)\n",
    "\n",
    "# ngrams of melodic entries\n",
    "# for chromatic, use:\n",
    "# piece.getMelodicEntries(interval_settings=('c', True, True), n=5)\n",
    "mel = piece.getMelodicEntries(n=4)\n",
    "mels_stacked = mel.stack().to_frame()\n",
    "mels_stacked.rename(columns =  {0:\"pattern\"}, inplace = True)\n",
    "\n",
    "# edit distance, based on side-by-side comparison of melodic ngrams\n",
    "# gets flexed and other similar soggetti\n",
    "dist = piece.getDistance(mel)\n",
    "dist_stack = dist.stack().to_frame()\n",
    "\n",
    "\n",
    "# filter distances to threshold.  <2 is good\n",
    "filtered_dist_stack = dist_stack[dist_stack[0] < 2]\n",
    "filtered_dist = filtered_dist_stack.reset_index()\n",
    "filtered_dist.rename(columns =  {'level_0':\"source\", 'level_1':'match'}, inplace = True)\n",
    "\n",
    "# Group the filtered distanced patterns\n",
    "full_list_of_matches = filtered_dist.groupby('source')['match'].apply(list).reset_index()\n",
    "\n",
    "for matches in full_list_of_matches[\"match\"]:\n",
    "    related_entry_list = mels_stacked[mels_stacked['pattern'].isin(matches)]\n",
    "    entry_array = related_entry_list.reset_index(level=1).rename(columns = {'level_1': \"voice\", 0: \"pattern\"})\n",
    "    offset_list = entry_array.index.to_list()\n",
    "    split_list = list(split_by_threshold(offset_list))\n",
    "    # here is the list of starting offsets of the original set of entries:  slist\n",
    "    slist = split_list[0]\n",
    "    temp = temp_dict_of_details(slist, entry_array, det, matches)\n",
    "\n",
    "    points = points.append(temp, ignore_index=True)\n",
    "    points['Presentation_Type'] = points['Time_Entry_Intervals'].apply(classify_by_offset)\n",
    "    points.drop_duplicates(subset=[\"First_Offset\"], keep='first', inplace = True)\n",
    "    points = points[points['Offsets'].apply(len) > 1]\n",
    "\n",
    "    test = [278.0, 286.0, 294.0, 298.0, 306.0, 310.0]\n",
    "\n",
    "    l = len(test)  \n",
    "    for item in range(3, l):\n",
    "        list_combinations = list(combinations(test, item))\n",
    "        for group in list_combinations:\n",
    "            group_time_ints = numpy.diff(group).tolist()\n",
    "            hidden_type = classify_by_offset(group_time_ints)\n",
    "            for item in group:\n",
    "    #         print(item)\n",
    "                array = group[entry_array.index.get_level_values(0).isin(item)]\n",
    "                short_offset_list = array.index.to_list()\n",
    "                time_ints = numpy.diff(array.index).tolist()\n",
    "                voice_list = array['voice'].to_list()\n",
    "                if 'PEN' in hidden_type:\n",
    "                    print(group)\n",
    "                    print(group_time_ints)\n",
    "                    print(hidden_type)\n",
    "                    hidden_pts.append(group_time_ints)\n",
    "                if 'ID' in hidden_type:\n",
    "                    print(group)\n",
    "                    print(group_time_ints)\n",
    "                    print(hidden_type)\n",
    "                    hidden_pts.append(group_time_ints)\n",
    "# len(split_list[0])           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3063b5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  This shows how the classifier works:\n",
    "\n",
    "if len(set(offset_diffs)) == 1 and len(offset_diffs) > 1:\n",
    "    print('This is a PEN')\n",
    "    # elif (len(offset_difference_list) %2 != 0) and (len(set(alt_list)) == 1):\n",
    "elif (len(offset_diffs) % 2 != 0) and (len(set(alt_list)) == 1) and (len(offset_diffs) >= 3):\n",
    "    print('This is an ID')\n",
    "elif len(offset_diffs) >= 1:\n",
    "    print('This is a FUGA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac85a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This shows how combinations works for a given set of time intervals\n",
    "offset_diffs = [12.0, 32.0, 12.0, 4.0]\n",
    "l = len(offset_diffs)\n",
    "# print(l)\n",
    "if l > 2:\n",
    "    for r in range(3, l):\n",
    "        print(r)\n",
    "        list_combinations = list(combinations(offset_diffs, r))\n",
    "#         for slist in list_combinations:\n",
    "        print(list_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ed6099",
   "metadata": {},
   "outputs": [],
   "source": [
    "slist = [278.0, 286.0, 294.0, 298.0, 306.0, 310.0]\n",
    "l = len(slist)\n",
    "# for r in range(3, 6):\n",
    "list_combinations = list(combinations(slist, 4))\n",
    "#     for tiny_list in list_combinations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0276a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b92435d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_offsets = [294.0, 298.0, 306.0, 310.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ab3b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_diffs = [4, 5, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63932bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_list = offset_diffs[::2]\n",
    "\n",
    "if len(set(offset_diffs)) == 1 and len(offset_diffs) > 1:\n",
    "    print('This is a PEN')\n",
    "    # elif (len(offset_difference_list) %2 != 0) and (len(set(alt_list)) == 1):\n",
    "elif (len(offset_diffs) % 2 != 0) and (len(set(alt_list)) == 1) and (len(offset_diffs) >= 3):\n",
    "    print('This is an ID')\n",
    "elif len(offset_diffs) >= 1:\n",
    "    print('This is a FUGA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7d7ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDistance2(self, df=None, n=3):\n",
    "    if df is None:\n",
    "            df = self.getMelodic('z', True, True)\n",
    "            df = self.getNgrams(df=df, n=n, exclude=['Rest'])\n",
    "    uni = df.stack().unique()\n",
    "    ser = pd.Series(uni)\n",
    "    df = pd.DataFrame.from_records(ser.apply(lambda cell: tuple(int(i) for i in cell.split(', '))))\n",
    "    cols = [(df - df.loc[i]).abs().apply(sum, axis=1) for i in df.index]\n",
    "    dist = pd.concat(cols, axis=1)\n",
    "    dist.columns = uni\n",
    "    dist.index = uni\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a50cbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24b9155",
   "metadata": {},
   "outputs": [],
   "source": [
    "melodic_ngram_length = 4\n",
    "edit_distance_threshold = 1\n",
    "nr = piece.getNoteRest()\n",
    "dur = piece.getDuration(df=nr)\n",
    "mel = piece.getMelodic(df=nr, kind='d', end=False)\n",
    "mel_ng = piece.getNgrams(df=mel, n=melodic_ngram_length)\n",
    "mel_ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8c1154",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = importedPiece.getDistance2(df=mel_ng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2e2abd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "61f8b281fdb479202292f4cbf8a4ff4ce2a75fed6d1a7d4f40edde65e5f6e284"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('intervals')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
